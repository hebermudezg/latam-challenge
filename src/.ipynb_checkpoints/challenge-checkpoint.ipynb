{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"../data/farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATAM Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proyecto de Ingenier√≠a de Datos\n",
    "\n",
    "Este proyecto aborda un desaf√≠o de ingenier√≠a de datos que consiste en procesar un conjunto de datos de tweets relacionados con protestas agr√≠colas. La idea es implementar unas funciones que sean √≥ptimas en tiempo y consumo de memoria. Adem√°s, se implementaron pruebas unitarias para garantizar la precisi√≥n de las funciones desarrolladas.\n",
    "\n",
    "## Enfoques\n",
    "\n",
    "### Enfoque Local\n",
    "Utiliza librer√≠as b√°sicas para procesar la informaci√≥n localmente.\n",
    "\n",
    "### Enfoque Distribuido\n",
    "Usa PySpark para demostrar c√≥mo se podr√≠an implementar soluciones similares pero para el procesamiento de grandes vol√∫menes de datos en entornos distribuidos, aunque los datos en este caso no son tan grandes.\n",
    "\n",
    "## Problema\n",
    "\n",
    "Se proporciona un archivo JSON de 398 MB con tweets. Se deben resolver los siguientes problemas:\n",
    "\n",
    "1. **Top 10 Fechas con M√°s Tweets**: Identificar las 10 fechas con m√°s tweets y el usuario con m√°s publicaciones en cada una.\n",
    "2. **Top 10 Emojis M√°s Usados**: Identificar los 10 emojis m√°s usados y su conteo.\n",
    "3. **Top 10 Usuarios M√°s Mencionados**: Identificar los 10 usuarios m√°s influyentes seg√∫n el conteo de menciones (@).\n",
    "\n",
    "Cada problema se resolver√° optimizando el tiempo de ejecuci√≥n y el uso de memoria.\n",
    "\n",
    "## Pruebas Unitarias\n",
    "\n",
    "Se implementaron pruebas unitarias para cada una de las funciones desarrolladas, garantizando as√≠ la exactitud de los resultados. Las pruebas aseguran que las funciones manejen correctamente los casos l√≠mite y los posibles errores. A continuaci√≥n se detallan las pruebas realizadas:\n",
    "\n",
    "1. **Top 10 Fechas con M√°s Tweets**:\n",
    "    - **Pruebas B√°sicas**: Verificar que las funciones `q1_time` y `q1_memory` identifiquen correctamente las fechas con m√°s tweets y el usuario m√°s activo en esas fechas.\n",
    "    - **Casos L√≠mite**: Verificar el comportamiento de las funciones cuando hay tweets con fechas faltantes o formatos de fecha incorrectos, manejando estos casos con excepciones y retornando resultados consistentes.\n",
    "\n",
    "2. **Top 10 Emojis M√°s Usados**:\n",
    "    - **Pruebas B√°sicas**: Verificar que las funciones `q2_time` y `q2_memory` identifiquen correctamente los emojis m√°s usados y su conteo.\n",
    "    - **Casos L√≠mite**: Verificar el comportamiento de las funciones cuando hay tweets con contenido faltante, asegurando que los emojis se cuenten correctamente y que los casos con contenido faltante sean manejados sin causar errores.\n",
    "\n",
    "3. **Top 10 Usuarios M√°s Mencionados**:\n",
    "    - **Pruebas B√°sicas**: Verificar que las funciones `q3_time` y `q3_memory` identifiquen correctamente los usuarios m√°s mencionados y su conteo.\n",
    "    - **Casos L√≠mite**: Verificar el comportamiento de las funciones cuando hay tweets con contenido faltante o sin menciones, asegurando que los usuarios se cuenten correctamente y que los casos con contenido faltante sean manejados adecuadamente.\n",
    "\n",
    "Las pruebas unitarias fueron dise√±adas para cubrir diferentes escenarios, incluyendo datos v√°lidos y casos l√≠mite, para asegurar que las funciones desarrolladas son medianamente fiables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>renderedContent</th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>outlinks</th>\n",
       "      <th>tcooutlinks</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>...</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>conversationId</th>\n",
       "      <th>lang</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>sourceLabel</th>\n",
       "      <th>media</th>\n",
       "      <th>retweetedTweet</th>\n",
       "      <th>quotedTweet</th>\n",
       "      <th>mentionedUsers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/ArjunSinghPanam/status/136...</td>\n",
       "      <td>2021-02-24 09:23:35+00:00</td>\n",
       "      <td>The world progresses while the Indian police a...</td>\n",
       "      <td>The world progresses while the Indian police a...</td>\n",
       "      <td>1364506249291784198</td>\n",
       "      <td>{'username': 'ArjunSinghPanam', 'displayname':...</td>\n",
       "      <td>[https://twitter.com/ravisinghka/status/136415...</td>\n",
       "      <td>[https://t.co/es3kn0IQAF]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1364506249291784198</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'url': 'https://twitter.com/RaviSinghKA/statu...</td>\n",
       "      <td>[{'username': 'narendramodi', 'displayname': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/PrdeepNain/status/13645062...</td>\n",
       "      <td>2021-02-24 09:23:32+00:00</td>\n",
       "      <td>#FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...</td>\n",
       "      <td>#FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...</td>\n",
       "      <td>1364506237451313155</td>\n",
       "      <td>{'username': 'PrdeepNain', 'displayname': 'Pra...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1364506237451313155</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>http://twitter.com/download/android</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>[{'thumbnailUrl': 'https://pbs.twimg.com/ext_t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'username': 'Kisanektamorcha', 'displayname'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/parmarmaninder/status/1364...</td>\n",
       "      <td>2021-02-24 09:23:22+00:00</td>\n",
       "      <td>‡®™‡©à‡®ü‡®∞‡©ã‡®≤ ‡®¶‡©Ä‡®Ü‡®Ç ‡®ï‡©Ä‡®Æ‡®§‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©±‡®¶‡©á‡®®‡®ú‡®º‡®∞ ‡®∞‡©±‡®ñ‡®¶‡©á ‡®π‡©ã‡®è \\n‡®Æ‡©á...</td>\n",
       "      <td>‡®™‡©à‡®ü‡®∞‡©ã‡®≤ ‡®¶‡©Ä‡®Ü‡®Ç ‡®ï‡©Ä‡®Æ‡®§‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©±‡®¶‡©á‡®®‡®ú‡®º‡®∞ ‡®∞‡©±‡®ñ‡®¶‡©á ‡®π‡©ã‡®è \\n‡®Æ‡©á...</td>\n",
       "      <td>1364506195453767680</td>\n",
       "      <td>{'username': 'parmarmaninder', 'displayname': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1364506195453767680</td>\n",
       "      <td>pa</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>http://twitter.com/download/android</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://twitter.com/ArjunSinghPanam/status/136...   \n",
       "1  https://twitter.com/PrdeepNain/status/13645062...   \n",
       "2  https://twitter.com/parmarmaninder/status/1364...   \n",
       "\n",
       "                       date  \\\n",
       "0 2021-02-24 09:23:35+00:00   \n",
       "1 2021-02-24 09:23:32+00:00   \n",
       "2 2021-02-24 09:23:22+00:00   \n",
       "\n",
       "                                             content  \\\n",
       "0  The world progresses while the Indian police a...   \n",
       "1  #FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...   \n",
       "2  ‡®™‡©à‡®ü‡®∞‡©ã‡®≤ ‡®¶‡©Ä‡®Ü‡®Ç ‡®ï‡©Ä‡®Æ‡®§‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©±‡®¶‡©á‡®®‡®ú‡®º‡®∞ ‡®∞‡©±‡®ñ‡®¶‡©á ‡®π‡©ã‡®è \\n‡®Æ‡©á...   \n",
       "\n",
       "                                     renderedContent                   id  \\\n",
       "0  The world progresses while the Indian police a...  1364506249291784198   \n",
       "1  #FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...  1364506237451313155   \n",
       "2  ‡®™‡©à‡®ü‡®∞‡©ã‡®≤ ‡®¶‡©Ä‡®Ü‡®Ç ‡®ï‡©Ä‡®Æ‡®§‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©±‡®¶‡©á‡®®‡®ú‡®º‡®∞ ‡®∞‡©±‡®ñ‡®¶‡©á ‡®π‡©ã‡®è \\n‡®Æ‡©á...  1364506195453767680   \n",
       "\n",
       "                                                user  \\\n",
       "0  {'username': 'ArjunSinghPanam', 'displayname':...   \n",
       "1  {'username': 'PrdeepNain', 'displayname': 'Pra...   \n",
       "2  {'username': 'parmarmaninder', 'displayname': ...   \n",
       "\n",
       "                                            outlinks  \\\n",
       "0  [https://twitter.com/ravisinghka/status/136415...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "\n",
       "                 tcooutlinks  replyCount  retweetCount  ...  quoteCount  \\\n",
       "0  [https://t.co/es3kn0IQAF]           0             0  ...           0   \n",
       "1                         []           0             0  ...           0   \n",
       "2                         []           0             0  ...           0   \n",
       "\n",
       "        conversationId  lang  \\\n",
       "0  1364506249291784198    en   \n",
       "1  1364506237451313155    en   \n",
       "2  1364506195453767680    pa   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...   \n",
       "\n",
       "                             sourceUrl          sourceLabel  \\\n",
       "0   http://twitter.com/download/iphone   Twitter for iPhone   \n",
       "1  http://twitter.com/download/android  Twitter for Android   \n",
       "2  http://twitter.com/download/android  Twitter for Android   \n",
       "\n",
       "                                               media retweetedTweet  \\\n",
       "0                                               None            NaN   \n",
       "1  [{'thumbnailUrl': 'https://pbs.twimg.com/ext_t...            NaN   \n",
       "2                                               None            NaN   \n",
       "\n",
       "                                         quotedTweet  \\\n",
       "0  {'url': 'https://twitter.com/RaviSinghKA/statu...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "\n",
       "                                      mentionedUsers  \n",
       "0  [{'username': 'narendramodi', 'displayname': '...  \n",
       "1  [{'username': 'Kisanektamorcha', 'displayname'...  \n",
       "2                                               None  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripci√≥n de las Columnas del DataFrame\n",
    "\n",
    "1. **url**: La URL del tweet.\n",
    "2. **date**: La fecha y hora en que se cre√≥ el tweet, en formato UTC.\n",
    "3. **content**: El texto del tweet.\n",
    "4. **renderedContent**: El contenido renderizado del tweet (puede ser igual a `content`).\n",
    "5. **id**: El identificador √∫nico del tweet.\n",
    "6. **user**: Informacion sobre usuario que public√≥ el tweet.\n",
    "7. **outlinks**: Enlaces externos incluidos en el tweet.\n",
    "8. **tcooutlinks**: Enlaces acortados de Twitter incluidos en el tweet.\n",
    "9. **replyCount**: N√∫mero de respuestas al tweet.\n",
    "10. **retweetCount**: N√∫mero de retweets del tweet.\n",
    "11. **likeCount**: N√∫mero de \"me gusta\" que recibi√≥ el tweet.\n",
    "12. **quoteCount**: N√∫mero de veces que el tweet fue citado.\n",
    "13. **conversationId**: Identificador de la conversaci√≥n a la que pertenece el tweet.\n",
    "14. **lang**: El idioma del tweet, en formato de c√≥digo BCP 47.\n",
    "15. **source**: La fuente desde donde se public√≥ el tweet (por ejemplo, \"Twitter Web Client\").\n",
    "16. **sourceUrl**: URL de la fuente desde donde se public√≥ el tweet.\n",
    "17. **sourceLabel**: Etiqueta de la fuente desde donde se public√≥ el tweet.\n",
    "18. **media**: Informaci√≥n sobre los medios incluidos en el tweet (im√°genes, videos, etc.).\n",
    "19. **retweetedTweet**: Informaci√≥n sobre el tweet original si este es un retweet.\n",
    "20. **quotedTweet**: Informaci√≥n sobre el tweet citado.\n",
    "21. **mentionedUsers**: Usuarios mencionados en el tweet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfoque Local\n",
    "---\n",
    "\n",
    "Las funciones `qx_time` y `qx_memory` fueron optimizadas para tiempo y memoria respectivamente. Para `q_time`, se utiliz√≥ `defaultdict` para contar tweets por fecha y usuario, procesando el archivo JSON l√≠nea por l√≠nea con `open` y `json.loads`, lo que permiti√≥ una r√°pida conversi√≥n de cada l√≠nea en un diccionario de Python. Los resultados se calcularon ordenando y agregando eficientemente los datos. Para `q_memory`, se implementaron generadores (`tweet_generator`) que leen el archivo l√≠nea por l√≠nea, reduciendo significativamente el uso de memoria. Al igual que en `q_time`, `defaultdict` se utiliz√≥ para llevar un conteo incremental de tweets, emojis o menciones, evitando cargar todo el archivo en memoria y optimizando as√≠ el rendimiento en t√©rminos de consumo de recursos. Aunque la librer√≠a pandas podr√≠a ser eficiente en algunos casos, se opt√≥ por estos enfoques para manejar eficientemente grandes vol√∫menes de datos.\n",
    "\n",
    "### Las Top 10 Fechas con M√°s Tweets y el Usuario M√°s Activo en Cada Fecha\n",
    "\n",
    "| Funci√≥n         | Tiempo de Ejecuci√≥n (s) | Uso de Memoria (MiB) |\n",
    "|-----------------|--------------------------|----------------------|\n",
    "| `q1_time`       | 2.96                     | 1.69                 |\n",
    "| `q1_memory`     | 2.83                     | 0.05                 |\n",
    "\n",
    "### Los Top 10 Emojis M√°s Usados con su Respectivo Conteo\n",
    "\n",
    "| Funci√≥n         | Tiempo de Ejecuci√≥n (s) | Uso de Memoria (MiB) |\n",
    "|-----------------|--------------------------|----------------------|\n",
    "| `q2_time`       | 3.20                     | 1.23                 |\n",
    "| `q2_memory`     | 3.24                     | 0.14                 |\n",
    "\n",
    "### Top 10 Usuarios M√°s Mencionados\n",
    "\n",
    "| Funci√≥n         | Tiempo de Ejecuci√≥n (s) | Uso de Memoria (MiB) |\n",
    "|-----------------|--------------------------|----------------------|\n",
    "| `q3_time`       | 2.65                     | 61.86                |\n",
    "| `q3_memory`     | 2.64                     | 0.27                 |\n",
    "\n",
    "\n",
    "\n",
    "NOTA: Se se ejecuta nuevamente las celdas puede cambiar brevemente el resultado. Se puede apreciar que qx_memory se ha logrado optimizar existosamente para consumo de momoria, en los qx_time los resultaods no son significativamente diferetes en terminos de tiempo que las funciones qx_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importando librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import time\n",
    "from memory_profiler import profile\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Las Top 10 Fechas con M√°s Tweets y el Usuario M√°s Activo en Cada Fecha</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Procesamiento completado exitosamente\n",
      "[INFO] Tiempo de ejecuci√≥n de q1_time: 2.96 segundos\n",
      "[INFO] Uso de memoria de q1_time: 1.69 MiB\n",
      "[INFO] Procesamiento completado exitosamente\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str, int]]:\n",
    "    \"\"\"\n",
    "    Esta funci√≥n toma la ruta de un archivo JSON que contiene tweets y devuelve una lista de las\n",
    "    10 fechas con m√°s tweets y el nombre del usuario que m√°s public√≥ en cada una de esas fechas,\n",
    "    optimizando para el uso de memoria.\n",
    "\n",
    "    Par√°metros:\n",
    "    file_path (str): La ruta al archivo JSON que contiene los tweets.\n",
    "\n",
    "    Retorna:\n",
    "    List[Tuple[datetime.date, str]]: Una lista de tuplas donde cada tupla contiene una fecha (datetime.date)\n",
    "    y el nombre del usuario que m√°s public√≥ en esa fecha.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Estructura para contar los tweets por fecha y por usuario\n",
    "        date_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        # Procesar el archivo l√≠nea por l√≠nea para minimizar el uso de memoria\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                tweet = json.loads(line) # Convertir a diccionario de Python\n",
    "                try:\n",
    "                    # Extraer y validar la fecha del tweet\n",
    "                    date_str = tweet.get('date', None)\n",
    "                    if date_str:\n",
    "                        date = datetime.strptime(date_str[:10], '%Y-%m-%d').date() #funcion problematica\n",
    "                    else:\n",
    "                        continue  # Saltar si no hay fecha\n",
    "\n",
    "                    # Extraer y validar el usuario del tweet\n",
    "                    user = tweet['user']['username'] if tweet['user'] and 'username' in tweet['user'] else None\n",
    "                    if user:\n",
    "                        date_counts[date][user] += 1  # Incrementar el conteo para la fecha y usuario correspondiente\n",
    "\n",
    "                except (KeyError, ValueError) as e:\n",
    "                    print(f\"[WARNING] Error procesando el tweet: {e}\")\n",
    "                    continue  # Saltar en caso de error de clave o valor\n",
    "\n",
    "        # Obtener las 10 fechas con m√°s tweets\n",
    "        top_dates = sorted(date_counts.items(), key=lambda x: sum(x[1].values()), reverse=True)[:10] #x[1] conteos por usuario\n",
    "\n",
    "        # Crear una lista de tuplas con las fechas y el nombre de usuario m√°s activo en cada fecha\n",
    "        result = [(date, max(users.items(), key=lambda x: x[1])[0]) for date, users in top_dates] #sum(users.values())\n",
    "\n",
    "        print(f\"[INFO] Procesamiento completado exitosamente\")\n",
    "        return result\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[ERROR] El archivo {file_path} no existe.\")\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "# Medir tiempo de ejecuci√≥n\n",
    "start_time = time.time()\n",
    "mem_usage_memory = memory_usage((q1_time, (file_path,)), interval=0.1, timeout=None)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"[INFO] Tiempo de ejecuci√≥n de q1_time: {end_time - start_time:.2f} segundos\")\n",
    "print(f\"[INFO] Uso de memoria de q1_time: {max(mem_usage_memory) - min(mem_usage_memory):.2f} MiB\")\n",
    "print(q1_time(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Procesamiento completado exitosamente\n",
      "[INFO] Tiempo de ejecuci√≥n de q1_memory: 2.83 segundos\n",
      "[INFO] Uso de memoria de q1_memory: 0.05 MiB\n",
      "[INFO] Procesamiento completado exitosamente\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "    Esta funci√≥n toma la ruta de un archivo JSON que contiene tweets y devuelve una lista de las\n",
    "    10 fechas con m√°s tweets y el nombre del usuario que m√°s public√≥ en cada una de esas fechas,\n",
    "    optimizando para el uso de memoria.\n",
    "\n",
    "    Par√°metros:\n",
    "    file_path (str): La ruta al archivo JSON que contiene los tweets.\n",
    "\n",
    "    Retorna:\n",
    "    List[Tuple[datetime.date, str]]: Una lista de tuplas donde cada tupla contiene una fecha (datetime.date)\n",
    "    y el nombre del usuario que m√°s public√≥ en esa fecha.\n",
    "    \"\"\"\n",
    "    # Estructura para contar los tweets por fecha y por usuario\n",
    "    date_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Funci√≥n generadora para procesar el archivo l√≠nea por l√≠nea\n",
    "    def tweet_generator(file_path):\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                for line in file:\n",
    "                    yield json.loads(line)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[ERROR] El archivo {file_path} no existe.\")\n",
    "            raise\n",
    "\n",
    "    # Usar el generador para procesar cada tweet\n",
    "    for tweet in tweet_generator(file_path):\n",
    "        try:\n",
    "            # Extraer y validar la fecha del tweet\n",
    "            date_str = tweet.get('date', None)\n",
    "            if date_str:\n",
    "                date = datetime.strptime(date_str[:10], '%Y-%m-%d').date()\n",
    "            else:\n",
    "                continue  # Saltar si no hay fecha\n",
    "\n",
    "            # Extraer y validar el usuario del tweet\n",
    "            user = tweet['user']['username'] if tweet['user'] and 'username' in tweet['user'] else None\n",
    "            if user:\n",
    "                date_counts[date][user] += 1  # Incrementar el conteo para la fecha y usuario correspondiente\n",
    "\n",
    "        except (KeyError, ValueError) as e:\n",
    "            print(f\"[WARNING] Error procesando el tweet: {e}\")\n",
    "            continue  # Saltar en caso de error de clave o valor\n",
    "\n",
    "    # Obtener las 10 fechas con m√°s tweets\n",
    "    top_dates = sorted(date_counts.items(), key=lambda x: sum(x[1].values()), reverse=True)[:10]\n",
    "\n",
    "    # Crear una lista de tuplas con las fechas y el nombre de usuario m√°s activo en cada fecha\n",
    "    result = [(date, max(users.items(), key=lambda x: x[1])[0]) for date, users in top_dates]\n",
    "\n",
    "    print(f\"[INFO] Procesamiento completado exitosamente\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# Medir tiempo de ejecuci√≥n\n",
    "start_time = time.time()\n",
    "mem_usage_memory = memory_usage((q1_memory, (file_path,)), interval=0.1, timeout=None)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"[INFO] Tiempo de ejecuci√≥n de q1_memory: {end_time - start_time:.2f} segundos\")\n",
    "print(f\"[INFO] Uso de memoria de q1_memory: {max(mem_usage_memory) - min(mem_usage_memory):.2f} MiB\")\n",
    "print(q1_memory(file_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Los Top 10 Emojis M√°s Usados con su Respectivo Conteo</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Iniciando procesamiento del archivo: ../data/farmers-protest-tweets-2021-2-4.json\n",
      "[INFO] Procesamiento completado exitosamente\n",
      "[INFO] Tiempo de ejecuci√≥n de q2_time: 3.20 segundos\n",
      "[INFO] Uso de memoria de q2_time: 1.23 MiB\n",
      "[INFO] Iniciando procesamiento del archivo: ../data/farmers-protest-tweets-2021-2-4.json\n",
      "[INFO] Procesamiento completado exitosamente\n",
      "[('üôè', 7286), ('üòÇ', 3072), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üèª', 2080), ('‚ù§', 1779), ('ü§£', 1668), ('üèΩ', 1218), ('üëá', 1108)]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import emoji\n",
    "\n",
    "def extract_emojis_from_text(text: str) -> List[str]:\n",
    "    return [c for c in text if c in emoji.EMOJI_DATA]\n",
    "\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Esta funci√≥n toma la ruta de un archivo JSON que contiene tweets y devuelve una lista de los\n",
    "    10 emojis m√°s usados con su respectivo conteo, optimizando para el uso de memoria.\n",
    "\n",
    "    Par√°metros:\n",
    "    file_path (str): La ruta al archivo JSON que contiene los tweets.\n",
    "\n",
    "    Retorna:\n",
    "    List[Tuple[str, int]]: Una lista de tuplas donde cada tupla contiene un emoji (str) y su conteo (int).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"[INFO] Iniciando procesamiento del archivo: {file_path}\")\n",
    "\n",
    "        # Estructura para contar los emojis\n",
    "        emoji_counts = defaultdict(int)\n",
    "\n",
    "        # Procesar el archivo l√≠nea por l√≠nea para minimizar el uso de memoria\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    tweet = json.loads(line)  # Convertir la l√≠nea en un diccionario de Python\n",
    "                    content = tweet.get('content', '')  # Obtener el contenido del tweet, por defecto vac√≠o si no existe\n",
    "                    if content is not None:\n",
    "                        # Extraer emojis del contenido del tweet\n",
    "                        emojis_in_tweet = extract_emojis_from_text(content)\n",
    "                        # Contar la frecuencia de cada emoji\n",
    "                        for em in emojis_in_tweet:\n",
    "                            emoji_counts[em] += 1\n",
    "                except (json.JSONDecodeError, KeyError, ValueError) as e:\n",
    "                    # Captura y registra cualquier error que ocurra durante el procesamiento del tweet\n",
    "                    print(f\"[WARNING] Error procesando el tweet: {e}\")\n",
    "                    continue\n",
    "\n",
    "        # Obtener los 10 emojis m√°s usados\n",
    "        top_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "        print(f\"[INFO] Procesamiento completado exitosamente\")\n",
    "        return top_emojis\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # Manejar el caso en que el archivo no exista\n",
    "        print(f\"[ERROR] El archivo {file_path} no existe.\")\n",
    "        return []\n",
    "\n",
    "# Medir tiempo de ejecuci√≥n\n",
    "start_time = time.time()\n",
    "mem_usage_memory = memory_usage((q2_time, (file_path,)), interval=0.1, timeout=None)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"[INFO] Tiempo de ejecuci√≥n de q2_time: {end_time - start_time:.2f} segundos\")\n",
    "print(f\"[INFO] Uso de memoria de q2_time: {max(mem_usage_memory) - min(mem_usage_memory):.2f} MiB\")\n",
    "\n",
    "# Llamar a la funci√≥n una vez m√°s para obtener el resultado\n",
    "result = q2_time(file_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Procesamiento completado exitosamente\n",
      "[INFO] Tiempo de ejecuci√≥n de q2_memory: 3.24 segundos\n",
      "[INFO] Uso de memoria de q2_memory: 0.14 MiB\n",
      "[INFO] Procesamiento completado exitosamente\n",
      "[('üôè', 7286), ('üòÇ', 3072), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üèª', 2080), ('‚ù§', 1779), ('ü§£', 1668), ('üèΩ', 1218), ('üëá', 1108)]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import emoji\n",
    "\n",
    "def extract_emojis_from_text(text):\n",
    "    return [c for c in text if c in emoji.EMOJI_DATA]\n",
    "\n",
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Esta funci√≥n toma la ruta de un archivo JSON que contiene tweets y devuelve una lista de los\n",
    "    10 emojis m√°s usados con su respectivo conteo, optimizando para el uso de memoria.\n",
    "\n",
    "    Par√°metros:\n",
    "    file_path (str): La ruta al archivo JSON que contiene los tweets.\n",
    "\n",
    "    Retorna:\n",
    "    List[Tuple[str, int]]: Una lista de tuplas donde cada tupla contiene un emoji (str) y su conteo (int).\n",
    "    \"\"\"\n",
    "\n",
    "    # Estructura para contar los emojis\n",
    "    emoji_counts = defaultdict(int)\n",
    "\n",
    "    # Funci√≥n generadora para procesar el archivo l√≠nea por l√≠nea\n",
    "    def tweet_generator(file_path): #iterador\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                for line in file:\n",
    "                    yield json.loads(line)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[ERROR] El archivo {file_path} no existe.\")\n",
    "            raise\n",
    "    # Usar el generador para procesar cada tweet\n",
    "    for tweet in tweet_generator(file_path):\n",
    "        try:\n",
    "            content = tweet.get('content', '')\n",
    "            if content is not None:\n",
    "                emojis_in_tweet = extract_emojis_from_text(content)\n",
    "                for em in emojis_in_tweet:\n",
    "                    emoji_counts[em] += 1\n",
    "        except KeyError as e:\n",
    "            print(f\"[WARNING] Error procesando el tweet: {e}\")\n",
    "\n",
    "    # Obtener los 10 emojis m√°s usados\n",
    "    top_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    print(f\"[INFO] Procesamiento completado exitosamente\")\n",
    "    return top_emojis\n",
    "\n",
    "\n",
    "# Medir tiempo de ejecuci√≥n\n",
    "start_time = time.time()\n",
    "mem_usage_memory = memory_usage((q2_memory, (file_path,)), interval=0.1, timeout=None)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"[INFO] Tiempo de ejecuci√≥n de q2_memory: {end_time - start_time:.2f} segundos\")\n",
    "print(f\"[INFO] Uso de memoria de q2_memory: {max(mem_usage_memory) - min(mem_usage_memory):.2f} MiB\")\n",
    "\n",
    "# Llamar a la funci√≥n una vez m√°s para obtener el resultado\n",
    "result = q2_memory(file_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Top 10 Hist√≥rico de Usuarios M√°s Influyentes en Funci√≥n del Conteo de las Menciones (@)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Iniciando procesamiento del archivo: ../data/farmers-protest-tweets-2021-2-4.json\n",
      "[INFO] Procesamiento completado exitosamente\n",
      "[INFO] Tiempo de ejecuci√≥n de q3_time: 2.65 segundos\n",
      "[INFO] Uso de memoria de q3_time: 61.86 MiB\n",
      "[INFO] Iniciando procesamiento del archivo: ../data/farmers-protest-tweets-2021-2-4.json\n",
      "[INFO] Procesamiento completado exitosamente\n",
      "[('@narendramodi', 2261), ('@Kisanektamorcha', 1836), ('@RakeshTikaitBKU', 1639), ('@PMOIndia', 1422), ('@RahulGandhi', 1125), ('@GretaThunberg', 1046), ('@RaviSinghKA', 1015), ('@rihanna', 972), ('@UNHumanRights', 962), ('@meenaharris', 925)]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "def extract_mentions(s: str) -> List[str]:\n",
    "    return re.findall(r'@\\w+', s)\n",
    "\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Esta funci√≥n toma la ruta de un archivo JSON que contiene tweets y devuelve una lista de los\n",
    "    10 usuarios m√°s mencionados con su respectivo conteo, optimizando para el uso de memoria.\n",
    "\n",
    "    Par√°metros:\n",
    "    file_path (str): La ruta al archivo JSON que contiene los tweets.\n",
    "\n",
    "    Retorna:\n",
    "    List[Tuple[str, int]]: Una lista de tuplas donde cada tupla contiene un usuario (str) y su conteo de menciones (int).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"[INFO] Iniciando procesamiento del archivo: {file_path}\")\n",
    "\n",
    "        # Estructura para contar las menciones\n",
    "        mention_counts = defaultdict(int)\n",
    "\n",
    "        # Procesar el archivo l√≠nea por l√≠nea para minimizar el uso de memoria\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    tweet = json.loads(line)  # Convertir la l√≠nea en un diccionario de Python\n",
    "                    content = tweet.get('content', '')  # Obtener el contenido del tweet, por defecto vac√≠o si no existe\n",
    "                    if content is not None:\n",
    "                        # Extraer menciones del contenido del tweet\n",
    "                        mentions_in_tweet = extract_mentions(content)\n",
    "                        # Contar la frecuencia de cada menci√≥n\n",
    "                        for mention in mentions_in_tweet:\n",
    "                            mention_counts[mention] += 1\n",
    "                except (json.JSONDecodeError, KeyError, ValueError) as e:\n",
    "                    # Capturar y registrar cualquier error que ocurra durante el procesamiento del tweet\n",
    "                    print(f\"[WARNING] Error procesando el tweet: {e}\")\n",
    "                    continue\n",
    "\n",
    "        # Obtener los 10 usuarios m√°s mencionados\n",
    "        top_mentions = sorted(mention_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "        print(f\"[INFO] Procesamiento completado exitosamente\")\n",
    "        return top_mentions\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # Manejar el caso en que el archivo no exista\n",
    "        print(f\"[ERROR] El archivo {file_path} no existe.\")\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "# Medir tiempo de ejecuci√≥n\n",
    "start_time = time.time()\n",
    "mem_usage_memory = memory_usage((q3_time, (file_path,)), interval=0.1, timeout=None)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"[INFO] Tiempo de ejecuci√≥n de q3_time: {end_time - start_time:.2f} segundos\")\n",
    "print(f\"[INFO] Uso de memoria de q3_time: {max(mem_usage_memory) - min(mem_usage_memory):.2f} MiB\")\n",
    "\n",
    "# Llamar a la funci√≥n una vez m√°s para obtener el resultado\n",
    "result = q3_time(file_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Procesamiento completado exitosamente\n",
      "[INFO] Tiempo de ejecuci√≥n de q3_memory: 2.64 segundos\n",
      "[INFO] Uso de memoria de q3_memory: 0.27 MiB\n",
      "[INFO] Procesamiento completado exitosamente\n",
      "[('@narendramodi', 2261), ('@Kisanektamorcha', 1836), ('@RakeshTikaitBKU', 1639), ('@PMOIndia', 1422), ('@RahulGandhi', 1125), ('@GretaThunberg', 1046), ('@RaviSinghKA', 1015), ('@rihanna', 972), ('@UNHumanRights', 962), ('@meenaharris', 925)]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "def extract_mentions(s):\n",
    "    return re.findall(r'@\\w+', s)\n",
    "\n",
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Esta funci√≥n toma la ruta de un archivo JSON que contiene tweets y devuelve una lista de los\n",
    "    10 usuarios m√°s mencionados con su respectivo conteo, optimizando para el uso de memoria.\n",
    "\n",
    "    Par√°metros:\n",
    "    file_path (str): La ruta al archivo JSON que contiene los tweets.\n",
    "\n",
    "    Retorna:\n",
    "    List[Tuple[str, int]]: Una lista de tuplas donde cada tupla contiene un usuario (str) y su conteo de menciones (int).\n",
    "    \"\"\"\n",
    "    # Estructura para contar las menciones\n",
    "    mention_counts = defaultdict(int)\n",
    "\n",
    "    # Funci√≥n generadora para procesar el archivo l√≠nea por l√≠nea\n",
    "    def tweet_generator(file_path): #iterador\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                for line in file:\n",
    "                    yield json.loads(line)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[ERROR] El archivo {file_path} no existe.\")\n",
    "            raise\n",
    "\n",
    "    # Usar el generador para procesar cada tweet\n",
    "    for tweet in tweet_generator(file_path):\n",
    "        try:\n",
    "            content = tweet.get('content', '')\n",
    "            if content is not None:\n",
    "                mentions_in_tweet = extract_mentions(content)\n",
    "                for mention in mentions_in_tweet:\n",
    "                    mention_counts[mention] += 1\n",
    "        except KeyError as e:\n",
    "            print(f\"[WARNING] Error procesando el tweet: {e}\")\n",
    "\n",
    "    # Obtener los 10 usuarios m√°s mencionados\n",
    "    top_mentions = sorted(mention_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    print(f\"[INFO] Procesamiento completado exitosamente\")\n",
    "    return top_mentions\n",
    "\n",
    "# Medir tiempo de ejecuci√≥n\n",
    "start_time = time.time()\n",
    "mem_usage_memory = memory_usage((q3_memory, (file_path,)), interval=0.1, timeout=None)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"[INFO] Tiempo de ejecuci√≥n de q3_memory: {end_time - start_time:.2f} segundos\")\n",
    "print(f\"[INFO] Uso de memoria de q3_memory: {max(mem_usage_memory) - min(mem_usage_memory):.2f} MiB\")\n",
    "\n",
    "# Llamar a la funci√≥n una vez m√°s para obtener el resultado\n",
    "result = q3_memory(file_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfoque Distribuido en la Nube\n",
    "---\n",
    "\n",
    "Las funciones `qx_time_spark` se crearon utilizando Spark, una tecnolog√≠a de computaci√≥n distribuida. Este enfoque es ideal para procesar grandes vol√∫menes de datos y aprovecha las capacidades de paralelizaci√≥n y escalabilidad de Spark que se va a ver reflejado en tiempos cortos de ejecuci√≥n. Sin embargo, para conjuntos de datos peque√±os, como los 398 MB de este ejercicio, las ventajas pueden no ser tan evidentes debido a la sobrecarga de configurar y gestionar cl√∫steres.\n",
    "\n",
    "### Las Top 10 Fechas con M√°s Tweets y el Usuario M√°s Activo en Cada Fecha\n",
    "\n",
    "| Funci√≥n             | Tiempo de Ejecuci√≥n (s) | Uso de Memoria (MiB) |\n",
    "|---------------------|--------------------------|----------------------|\n",
    "| `q1_time_spark`     | 10.32                    | 9.09                 |\n",
    "\n",
    "### Los Top 10 Emojis M√°s Usados con su Respectivo Conteo\n",
    "\n",
    "| Funci√≥n             | Tiempo de Ejecuci√≥n (s) | Uso de Memoria (MiB) |\n",
    "|---------------------|--------------------------|----------------------|\n",
    "| `q2_time_spark`     | 2.40                     | 8.94                 |\n",
    "\n",
    "### Top 10 Usuarios M√°s Mencionados\n",
    "\n",
    "| Funci√≥n             | Tiempo de Ejecuci√≥n (s) | Uso de Memoria (MiB) |\n",
    "|---------------------|--------------------------|----------------------|\n",
    "| `q3_time_spark`     | 1.44                     | 0.13                 |\n",
    "\n",
    "\n",
    "\n",
    "## Ventajas de Usar un Enfoque Distribuido\n",
    "NOTA: Si se ejecutan nuevamente las celdas, los resultados pueden variar ligeramente. El consumo de momorya puede no ser una buena metrica en este caso por la dificulta del trackeo del consumo de momoria en entornos distribuidos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Las Top 10 Fechas con M√°s Tweets y el Usuario M√°s Activo en Cada Fecha</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/25 14:15:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n de q1_time_spark: 10.31771206855774 segundos\n",
      "Uso de memoria de q1_time_spark: 9.09375 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/25 14:16:12 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, to_date,split, udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import datetime\n",
    "from typing import List, Tuple\n",
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# Inicializar Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Twitter Mentions Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "def q1_time_spark(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "    Esta funci√≥n toma la ruta de un archivo JSON que contiene tweets y devuelve una lista de las\n",
    "    10 fechas con m√°s tweets y el nombre del usuario que m√°s public√≥ en cada una de esas fechas.\n",
    "\n",
    "    Par√°metros:\n",
    "    file_path (str): La ruta al archivo JSON que contiene los tweets.\n",
    "\n",
    "    Retorna:\n",
    "    List[Tuple[datetime.date, str]]: Una lista de tuplas donde cada tupla contiene una fecha (datetime.date)\n",
    "    y el nombre del usuario que m√°s public√≥ en esa fecha.\n",
    "    \"\"\"\n",
    "    # Cargar el archivo JSON en un DataFrame de Spark\n",
    "    df = spark.read.json(file_path)\n",
    "\n",
    "    # Convertir la columna 'date' a date\n",
    "    df = df.withColumn('date', to_date(col('date')))\n",
    "    \n",
    "    # Obtener las 10 fechas con m√°s tweets\n",
    "    top_dates = df.groupBy('date').count().orderBy('count', ascending=False).limit(10).collect()\n",
    "    \n",
    "    # Crear una lista de tuplas con las fechas y el nombre de usuario m√°s activo en cada fecha\n",
    "    result = []\n",
    "    for row in top_dates:\n",
    "        date = row['date']\n",
    "        top_user = df.filter(col('date') == date).groupBy('user.username').count().orderBy('count', ascending=False).first()['username']\n",
    "        result.append((date, top_user))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Medir tiempo de ejecuci√≥n\n",
    "start_time = time.time()\n",
    "mem_usage_time = memory_usage((q1_time_spark, (file_path,)), interval=0.1, timeout=None)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Tiempo de ejecuci√≥n de q1_time_spark: {end_time - start_time} segundos\")\n",
    "print(f\"Uso de memoria de q1_time_spark: {max(mem_usage_time) - min(mem_usage_time)} MiB\")\n",
    "print(q1_time_spark(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Los Top 10 Emojis M√°s Usados con su Respectivo Conteo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n de q2_time_spark: 2.4027657508850098 segundos\n",
      "Uso de memoria de q2_time_spark: 8.9375 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/25 14:16:19 WARN SimpleFunctionRegistry: The function extract_emojis_udf replaced a previously registered function.\n",
      "[Stage 73:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 100846), ('üôè', 7286), ('üòÇ', 3072), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üèª', 2080), ('‚ù§', 1779), ('ü§£', 1668), ('üèΩ', 1218)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "def extract_emojis_from_text(text):\n",
    "    return ''.join([c for c in text if c in emoji.EMOJI_DATA])\n",
    "\n",
    "def q2_time_spark(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Esta funci√≥n toma la ruta de un archivo JSON que contiene tweets y devuelve una lista de los\n",
    "    10 emojis m√°s usados con su respectivo conteo.\n",
    "\n",
    "    Par√°metros:\n",
    "    file_path (str): La ruta al archivo JSON que contiene los tweets.\n",
    "\n",
    "    Retorna:\n",
    "    List[Tuple[str, int]]: Una lista de tuplas donde cada tupla contiene un emoji (str) y su conteo (int).\n",
    "    \"\"\"\n",
    "    # Cargar el archivo JSON en un DataFrame de Spark\n",
    "    df = spark.read.json(file_path)\n",
    "    \n",
    "    # Extraer todos los emojis de los tweets\n",
    "    extract_emojis_udf = spark.udf.register(\"extract_emojis_udf\", extract_emojis_from_text)\n",
    "    df = df.withColumn('emojis', extract_emojis_udf(col('content')))\n",
    "    \n",
    "    # Explode la columna de emojis\n",
    "    df = df.withColumn('emoji', explode(split(col('emojis'), '')))\n",
    "    \n",
    "    # Contar la frecuencia de cada emoji\n",
    "    emoji_counts = df.groupBy('emoji').count().orderBy('count', ascending=False).limit(10)\n",
    "    \n",
    "    # Crear una lista de tuplas con los emojis y su conteo\n",
    "    result = [(row['emoji'], row['count']) for row in emoji_counts.collect()]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Medir tiempo de ejecuci√≥n\n",
    "start_time = time.time()\n",
    "mem_usage_time = memory_usage((q2_time_spark, (file_path,)), interval=0.1, timeout=None)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Tiempo de ejecuci√≥n de q2_time_spark: {end_time - start_time} segundos\")\n",
    "print(f\"Uso de memoria de q2_time_spark: {max(mem_usage_time) - min(mem_usage_time)} MiB\")\n",
    "print(q2_time_spark(file_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Top 10 Hist√≥rico de Usuarios M√°s Influyentes en Funci√≥n del Conteo de las Menciones (@)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n de q3_time_spark: 1.4450087547302246 segundos\n",
      "Uso de memoria de q3_time_spark: 0.125 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@narendramodi', 2261), ('@Kisanektamorcha', 1836), ('@RakeshTikaitBKU', 1639), ('@PMOIndia', 1422), ('@RahulGandhi', 1125), ('@GretaThunberg', 1046), ('@RaviSinghKA', 1015), ('@rihanna', 972), ('@UNHumanRights', 962), ('@meenaharris', 925)]\n"
     ]
    }
   ],
   "source": [
    "# funci√≥n extract_mentions\n",
    "import re\n",
    "def extract_mentions(s):\n",
    "    return re.findall(r'@\\w+', s)\n",
    "\n",
    "# extract_mentions como UDF\n",
    "extract_mentions_udf = udf(extract_mentions, ArrayType(StringType()))\n",
    "\n",
    "def q3_time_spark(file_path: str) -> List[Tuple[str, int]]:\n",
    "    df = spark.read.json(file_path)\n",
    "    df = df.withColumn('mentions', explode(extract_mentions_udf(col('content'))))\n",
    "    mention_counts = df.groupBy('mentions').count().orderBy('count', ascending=False).limit(10)\n",
    "    result = [(row['mentions'], row['count']) for row in mention_counts.collect()]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Medir tiempo de ejecuci√≥n\n",
    "start_time = time.time()\n",
    "mem_usage_time = memory_usage((q3_time_spark, (file_path,)), interval=0.1, timeout=None)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Tiempo de ejecuci√≥n de q3_time_spark: {end_time - start_time} segundos\")\n",
    "print(f\"Uso de memoria de q3_time_spark: {max(mem_usage_time) - min(mem_usage_time)} MiB\")\n",
    "print(q3_time_spark(file_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ventajas de Usar un Enfoque Distribuido\n",
    "\n",
    "El enfoque distribuido es ideal para procesar grandes vol√∫menes de datos. Plataformas como Databricks, AWS Glue, Azure Synapse Analytics y Google BigQuery facilitan la gesti√≥n de cl√∫steres de computaci√≥n distribuida.\n",
    "\n",
    "1. **Escalabilidad**: Permite a√±adir nodos al cl√∫ster para manejar m√°s datos, asegurando un rendimiento consistente.\n",
    "2. **Eficiencia de Procesamiento**: Tecnolog√≠as como Apache Spark procesan datos en paralelo, reduciendo el tiempo de ejecuci√≥n. (puro hardware)\n",
    "3. **Tolerancia a Fallos**: Los sistemas distribuidos reasignan tareas si un nodo falla, garantizando continuidad en el procesamiento.\n",
    "4. **Flexibilidad y Facilidad de Uso**: Proveen entornos integrados con diversas integraciones y herramientas.\n",
    "\n",
    "Sin embargo, para conjuntos de datos peque√±os, como los 398 MB de este ejercicio, las ventajas pueden no ser evidentes. La sobrecarga de configurar y gestionar cl√∫steres puede superar los beneficios del procesamiento paralelo.\n",
    "\n",
    "### Consideraciones de Escalabilidad\n",
    "\n",
    "Para conjuntos de datos m√°s grandes, usar Spark en un cl√∫ster distribuido es eficiente y escalable. A medida que el tama√±o de los datos crece, el enfoque distribuido maneja la carga adicional sin degradar el rendimiento, algo dif√≠cil de lograr con un enfoque local.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
